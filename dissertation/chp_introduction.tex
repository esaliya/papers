\chapter{Introduction}
\label{ch:introduction}


\begin{center}
\textbf{Thesis Statement}

\todo{a thesis statement}
\end{center}

\todo{Change the introduction to focus more on the systematic study of performance rather classification}

The big data phenomenon has evolved from being a hype to a norm within a short period of time. Google pioneered the concept of big data processing with the advent of MapReduce~\cite{Dean:2004:MSD:1251254.1251264} framework to analyze the large collection of web data within the company. The concept gained wide publicity for reasons such as the ease of programming, built-in fault tolerance, and horizontal scalability over commodity clusters. Apache Hadoop~\cite{White:2012:HDG:2285539}, the open source implementation of MapReduce, emerged as a result of this interest and made large scale data processing available to other companies and academia. A number of big data frameworks including the popular Apache Spark, Flink, and Storm have spurred since Hadoop supporting complex batch and streaming data analytics beyond MapReduce. 

While the early stages of big data development has been about providing data storage and analytic capabilities, the recent years have seen a growing interest to improve performance and scalability. Leveraging HPC infrastructure for high performance big data analytics  has also become an area of interest complimentary to the general idea of improving performance. It is identified as the convergence of big data and HPC in~\cite{bigdataconvergence}. 

--------------------

\textcolor{blue}{--resuable paras---}
Recent years have seen an explosion of data challenging every aspect of conventional computing from data acquisition, transmission, storage, and to processing. The trend is predicted to double each  year, and both the industry and academia are working in tandem to bring innovating solutions to these big data problems. These developments have produced a number of frameworks catering the diverse needs of big data. Apache Hadoop, Spark, and Flink are just a few of the popular ones among the 300+ entities available as open source software in \ac{ABDS}.

\textcolor{blue}{-----OLD INTRO-----}
Large scale data has dominated every aspect of computing over the past few years and will continue to do so with an ever increasing trend. Big Data applications come in all shapes and sizes where most of the commercially driven use cases tend to have relatively less complex applications consuming colossal amounts of data compared to highly complex applications operating on moderate amounts of data in the Science and Engineering research driven use cases. The scope of this work is pivoted around this research driven end of the Big Data applications’ spectrum, which lacks comprehensive performance studies in contrast to its counterparts – high performance scientific simulations and commercial applications.

A benchmark suite, either paper and pencil or code specification, is often the answer that could be used to measure, evaluate, and compare computer architectures and software stacks for performance metrics. This approach has been successful in both the traditional \ac{HPC} and database communities with popular benchmarks such as LINPACK~\cite{Dongarra1988,linpack} and TPC~\cite{tpc}. The reason for its success is due to the fact that the structure of computation, communication, and data access are mostly uniform and well aligned with those of the real applications. In fact, these benchmarks were often derived from or resembled real applications like in the case of NAS parallel benchmarks. This uniformity of factors across applications, however, breaks with the diversity [3] of Big Data use cases, thus necessitating a particular Big Data benchmark identifying the class of problems it represents. In light of this, we believe it is necessary and timely to introduce a systematic approach to characterize the diverse range of Big Data benchmarks to illustrate their coverage and to identify the areas that need further studying. We propose to use Ogres [4-6], a multidimensional multifaceted classification of Big Data applications as a solution. Ogres are similar in approach to Berkeley Dwarfs [7], i.e. they capture classes of Big Data problems.  They extend beyond dwarfs with the argument that a single criterion fails to capture the diversity, thereby introducing multiple dimensions (views) of classification – problem architecture, execution, data source and style, and processing – each with multiple facets. We follow up with the details of this classification in section 2.

Despite the lack of a systematic approach to classification, there have been some propitious benchmarks, such as  BigDataBench [8], HiBench [9], and Graph500 [10], introduced in the Big Data domain. BigDataBench is for applications from internet services while HiBench is similar, but stresses MapReduce [11] styled data analysis, and Graph500 is based on graph search to exercise supercomputing systems; further illustrating the diversity of Big Data use cases. We introduce new benchmarks to represent the application area of general machine learning (GML). In particular, we have selected MDS and clustering classes that are seldom present in the commercially driven benchmarks, yet are salient among Big Data use cases [3, 4]. Our decision is further based on two reasons. First, the implementations of these naturally follow map-collective [4, 12] pattern with iterations, both are computation and communication intensive, and communications are often global compared to local neighbor communications found in HPC applications. These features tend to be similar in other candidates of the GML category, so they too would benefit from studying MDS and clustering. Second, we extensively work with gene sequence and other health data to provide novel means of finding similarities and visualizing them in 3 dimensions (3D) [13-16], where MDS and clustering are the key components. A typical run of the pipeline (see Figure 5) based on our experience for a moderate dataset even on 1000 cores would take at least a couple of days making it pertinent to study performance characteristics of these classes. 

We set the scope and purpose this research, following our reasoning, to research and evaluate the Ogre approach by classifying existing Big Data benchmarks into Ogres, identifying their facets coverage, and introducing new benchmarks and evaluating them towards making a comprehensive a Big Data benchmark set. We supplement the research with a scalable parallel interoperable data analytics (SPIDAL) library [17, 18] comprising efficient implementations of the aforementioned Ogres that we have developed in-house and made open source [18].

The rest of the chapters are organized as follows. Chapter 2 presents similar efforts in the literature on setting standards to Big Data benchmarking, and chapter 3 introduces the concept of Ogres, facets of Big Data, and Ogre classification of benchmarks. Chapter 4 presents MDS and clustering, and their use cases. Chapter 5 illustrates current performance results and discusses our experience of using Java and related technologies for complex Big Data problems. Chapter 6 appraises the landscape of existing benchmarks coming from HPC, databases, and Big Data. We end our discussion presenting a summary and the research plan in chapter 7.

\vspace{1em}
