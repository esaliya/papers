\chapter{Benchmark Classification}
\label{ch:bmclassification}

The big data domain being relatively new compared to scientific simulations has still produced a number of benchmarks as discussed in \cref{ch:relatedwork}. While having a collection of benchmarks is helpful in addressing the diversity of big data applications, a systematic classification is necessary to identifying their similarity and coverage. BigDataBench~\cite{handbookofbigdatabench}, for example, provides a mechanism to pick a subset of its benchmarks in evaluating a big data system~\cite{DBLP:journals/corr/JiaZWHMYLL14} based on the micro architectural level \code{perf} metrics available in Linux operating systems. The idea is to represent each benchmark as a vector of different runtime metrics, such as load and store, cache misses, \ac{TLB} misses, and off-core requests. A total of 45 metrics spanning across 9 categories is used to in BigDataBench. The vectors are then processed through \ac{PCA} to remove correlated metrics and clustered using K-means algorithm. A representative benchmark from each cluster is selected to produce the final subset of benchmarks. Also, a hierarchical clustering algorithm is run on the \ac{PCA} output to produce a dendrogram showing the similarity between benchmarks. 

While runtime characteristics is an important measure in studying about benchmarks, the downside is that one needs to first run and collect those metrics before being able to compare a new benchmark against existing ones. Also, such schemes do not capture the high level features of the benchmark. Berkeley Dwarfs~\cite{Asanovic:2009:VPC:1562764.1562783}, as elaborated in \cref{ch:relatedwork}, presents a pattern based approach to benchmark classification. The Dwarfs classification, however, is intended for \ac{HPC} applications and is limited in applicability to cover the diverse range of big data applications. 

Ogres~\cite{ogres} aim to solve the aforementioned limitations by providing a richer multifaceted classification (see \cref{ch:relatedwork}). The Convergence Diamonds~\cite{diamonds} extend Ogres to include both big data and big simulations by adding facets to capture the features of the model and data separately. In this chapter, we present a classification of existing benchmarks using the Convergence Diamonds model. We start by introducing its facets and explaining the difference between the model and the data.

\begin{figure}[!h]
\centering
\includegraphics[width=1\columnwidth]{figures/fig_ogres}
\caption{Benchmark classification with convergence diamonds}
\label{fig:fig_ogres}
\end{figure}

Figure~\ref{fig:fig_ogres} shows the four axes similar to the Ogres. 
\todo{Explain why the D and M characters are next to facets and what are the prominent facets}
\todo{Then provide the table of classification}